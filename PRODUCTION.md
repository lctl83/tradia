# üñ•Ô∏è Guide de d√©ploiement Production - DELL PowerEdge R760

## Sp√©cifications du serveur

| Composant | Configuration |
|-----------|---------------|
| **CPU** | Intel Xeon Gold 6526Y (16C/32T @ 2.8 GHz, Turbo) |
| **RAM** | 256 Go DDR5 @ 5600 MT/s |
| **GPU** | NVIDIA L40S 48 Go VRAM (PCIe, 350W) |
| **Stockage** | 1.92 To SSD SAS + 1.92 To NVMe |

## üöÄ Optimisations recommand√©es

### 1. Configuration GPU pour Ollama

```bash
# V√©rifier que le GPU est d√©tect√©
nvidia-smi

# Afficher les processus GPU
nvidia-smi -l 1

# V√©rifier CUDA
nvcc --version
```

**Si le GPU n'est pas utilis√© par Ollama** :
```bash
# Installer/mettre √† jour les drivers NVIDIA
sudo apt update
sudo apt install nvidia-driver-535 nvidia-cuda-toolkit

# Red√©marrer
sudo reboot

# Apr√®s red√©marrage, v√©rifier
ollama run llama3.2:1b --verbose 2>&1 | grep -i gpu
```

### 2. Mod√®les recommand√©s pour Tradia

| Mod√®le | VRAM | Vitesse | Qualit√© | Usage |
|--------|------|---------|---------|-------|
| `ministral-3:latest` | ~8-15 Go | ‚ö°‚ö°‚ö°‚ö° Rapide | ‚≠ê‚≠ê‚≠ê | **Par d√©faut** - R√©ponses rapides |
| `magistral:latest` | ~15-24 Go | ‚ö°‚ö° Lent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **Qualitatif** - Meilleur raisonnement |

> **Note** : Avec 48 Go de VRAM, les deux mod√®les tournent confortablement. Vous pouvez m√™me les charger simultan√©ment.

```bash
# Installer les mod√®les recommand√©s
ollama pull ministral-3:latest
ollama pull magistral:latest

# Tester les performances
time ollama run ministral-3:latest "Traduis en anglais: Bonjour le monde"
time ollama run magistral:latest "Traduis en anglais: Bonjour le monde"
```

### 3. Configuration Ollama optimis√©e

Cr√©er `/etc/systemd/system/ollama.service.d/override.conf` :

```ini
[Service]
# √âcouter sur toutes les interfaces (si frontend distant)
Environment="OLLAMA_HOST=0.0.0.0:11434"

# Nombre de requ√™tes parall√®les
Environment="OLLAMA_NUM_PARALLEL=4"

# Garder les mod√®les en m√©moire GPU plus longtemps (5 minutes)
Environment="OLLAMA_KEEP_ALIVE=5m"

# Utiliser toute la VRAM disponible
Environment="OLLAMA_GPU_MEMORY_FRACTION=0.95"
```

Puis :
```bash
sudo systemctl daemon-reload
sudo systemctl restart ollama
```

### 4. D√©ploiement en production

```bash
# Utiliser la configuration de production
docker compose -f docker-compose.prod.yml up -d --build

# V√©rifier les logs
docker compose -f docker-compose.prod.yml logs -f tradia

# V√©rifier l'√©tat
docker compose -f docker-compose.prod.yml ps
```

## üìä Monitoring GPU

### Script de surveillance

Cr√©er `monitor-gpu.sh` :

```bash
#!/bin/bash
watch -n 1 "nvidia-smi --query-gpu=name,temperature.gpu,utilization.gpu,memory.used,memory.total --format=csv"
```

### M√©triques cl√©s √† surveiller

| M√©trique | Valeur normale | Alerte si |
|----------|----------------|-----------|
| Temp√©rature GPU | < 75¬∞C | > 85¬∞C |
| Utilisation GPU | Variable | 100% constant |
| M√©moire GPU | < 45 Go | > 47 Go |
| Utilisation CPU | < 50% | > 80% constant |

## üîí S√©curit√© production

### Firewall

```bash
# Autoriser uniquement les ports n√©cessaires
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw deny 8000/tcp  # Bloquer l'acc√®s direct, passer par Traefik
sudo ufw deny 11434/tcp  # Bloquer Ollama de l'ext√©rieur
sudo ufw enable
```

### Limiter l'acc√®s Ollama

Si le frontend est sur le m√™me serveur, Ollama ne doit √©couter que localement :
```bash
# Dans /etc/systemd/system/ollama.service.d/override.conf
Environment="OLLAMA_HOST=127.0.0.1:11434"
```

## üìà Benchmarks attendus

### Avec `ministral-3:latest` (‚ö° Rapide)

| Op√©ration | Temps attendu |
|-----------|---------------|
| Traduction (100 mots) | ~1-2 secondes |
| Correction (500 mots) | ~2-3 secondes |
| Reformulation (500 mots) | ~2-4 secondes |
| Compte rendu (1000 mots) | ~4-6 secondes |

### Avec `magistral:latest` (‚ú® Qualitatif)

| Op√©ration | Temps attendu |
|-----------|---------------|
| Traduction (100 mots) | ~3-5 secondes |
| Correction (500 mots) | ~5-8 secondes |
| Reformulation (500 mots) | ~6-10 secondes |
| Compte rendu (1000 mots) | ~10-15 secondes |

## üîÑ Maintenance

### Mise √† jour des mod√®les

```bash
# Mettre √† jour les mod√®les
ollama pull ministral-3:latest
ollama pull magistral:latest

# Nettoyer les anciens mod√®les
ollama list
ollama rm ancien-modele
```

### Sauvegarde

```bash
# Sauvegarder la configuration
cp docker-compose.prod.yml /backup/tradia/
cp .env /backup/tradia/

# Les mod√®les Ollama sont dans ~/.ollama/models
```

---

**Configuration valid√©e pour** : DELL PowerEdge R760 + NVIDIA L40S 48 Go
